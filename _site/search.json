[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This blog consists of the 5 “Mini-Projects” I have completed during a semester of Math Stat. Each Project correlates with a topic we covered in class, and the attached reflection ties all of the projects together."
  },
  {
    "objectID": "posts/05-p-value/index.html",
    "href": "posts/05-p-value/index.html",
    "title": "Mini Project 5",
    "section": "",
    "text": "“All work presented is my own, and I have followed all rules for collaboration. I have not used generative AI on this project.”\n\nI think the authors mean that statistical significance being used less means we will rely less solely on the p-value for statistical significance and use statistical thinking in a more contextual way. An example of this would be if you find a small p-value for something with a relatively small difference 9it might not mean anything in the real world, like finding a significant difference between the weight of 2 ants… who cares. It’s just more about being more thoughtful and open to thinking of possibilities besides the answer the p-value gives us.\nUsing an arbitrary number like p &lt; 0.05 to declare results significant or not leads to a possible false sense of certainty or maybe the absence of an effect you thought was stronger than it is. Labeling something as statistically significant can lead people to believe that the association is true and important, and labeling something not statistically significant can mislead people to think the association is useless and false. The problem with this is that the p-value alone can’t tell us this information. A p-value of 0.049 and 0.051 are treated as categorically different under the 0.05 rule, when in reality the actual difference in evidence they provide is minimal.\nBased on the information, I strongly agree with what the author is saying, especially for scientific publishing. Relying on statistical significance as a gatekeeper for reporting and highlighting findings is bad for the integrity of scientific publishing and research. Instead of relying on the p-value, researchers should be more open and honest with all of their results regardless of statistical significance. This could be through providing the size of effects, more confidence intervals and just considering the broader context of the research.\nI agree strongly again that the one size fits all approach to statistical inference is an inappropriate expectation. The authors explicitly state that it is impossible to find one majestic solution to replace the role of statistical significance and p-values. Scientific research is often exploratory and sometimes uncertain, and a one-size-fits all approach is an inappropriate expectation given the varying nature of research questions, data and contexts. Using thoughtful and contextual approaches seems to be the most fitting.\nStatistical thoughtfulness to me seems to represent a deep and comprehensive engagement with statistical aspects of research that goes beyond the application of formulas and the obtaining of statistical significance. It involves a critical and well rounded approach to design, analysis and interpretation grounded in the context of the research and the understanding of uncertainty. This can be done by clearly stating the research questions, reporting p-values as continuous quantities instead of significant or not, and explicitly discussing limitations and holes in research.\nI think the main problem these scientists are talking about is the way we label things and the language we use. When an average person who may not have statistical background hears that the findings of a study are not significant, they are going to take the researcher’s word for it and probably not understand the full context of the problem. The words significance and confidence can be misleading because they lead to overconfident claims and possibly misleading results. I agree with using the term compatibility instead because this way we think of p-values as measuring the compatibility between the hypothesis and the observed data, and don’t rely on them for statistical “significance”. There is a persistent confusion between statistical significance and actual importance that this use of language causes.\nA quote that stuck out to me is in section 1 on page 5, that says, “Don’t believe that your p-value gives the probability that chance alone produced the observed association or effect or the probability that your hypothesis test is true”. This quote stuck out because it directly addresses a very prevalent and fundamental misunderstanding of what a p-value actually represents, and I was blindly following what I had been taught about p-values until I read this paper. The notion that the null or alternative hypothesis are true or false based on the p-value is a long running misconception that leads to limited and often misinterpreted information. It made me think about how deeply ingrained this incorrect interpretation is and how much it might skew our research findings across various fields of study."
  },
  {
    "objectID": "posts/01-simulation/index.html",
    "href": "posts/01-simulation/index.html",
    "title": "Mini Project 1",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n“I have followed all rules for collaboration for this project, and I have not used generative AI on this project.”\n#Simulation for Y(min)~Normal(mu = 10, SD = 2)\n\nn &lt;- 5       # sample size\nmu &lt;- 10     # population mean\nsigma &lt;- 2   # population standard deviation\n\n# generate a random sample of n observations from a normal population\nsingle_sample &lt;- rnorm(n, mu, sigma) |&gt; round(2)\n# look at the sample\nsingle_sample \n\n[1]  9.67 13.74  8.57  9.32 12.34\n\n# compute the sample mean\nsample_min &lt;- min(single_sample)\n# look at the sample mean\nsample_min   \n\n[1] 8.57\n\n# generate a range of values that span the population\nplot_df &lt;- tibble(xvals = seq(mu - 4 * sigma, mu + 4 * sigma, length.out = 500)) |&gt;\n  mutate(xvals_density = dnorm(xvals, mu, sigma))\n\n## plot the population model density curve\nggplot(data = plot_df, aes(x = xvals, y = xvals_density)) +\n  geom_line() +\n  theme_minimal() +\n  ## add the sample points from your sample\n  geom_jitter(data = tibble(single_sample), aes(x = single_sample, y = 0),\n              width = 0, height = 0.005) +\n  ## add a line for the sample mean\n  geom_vline(xintercept = sample_min, colour = \"red\") +\n  labs(x = \"y\", y = \"density\",\n       title = \"Normal with Mu = 10 and sigma = 2\")\n\n\n\n\n\n\n\n\n#Simulation for Y(max)~Normal(mu = 10, SD = 2)\n\nsample_max &lt;- max(single_sample)\n# look at the sample mean\nsample_max   \n\n[1] 13.74\n\n# generate a range of values that span the population\nplot_df &lt;- tibble(xvals = seq(mu - 4 * sigma, mu + 4 * sigma, length.out = 500)) |&gt;\n  mutate(xvals_density = dnorm(xvals, mu, sigma))\n\n## plot the population model density curve\nggplot(data = plot_df, aes(x = xvals, y = xvals_density)) +\n  geom_line() +\n  theme_minimal() +\n  ## add the sample points from your sample\n  geom_jitter(data = tibble(single_sample), aes(x = single_sample, y = 0),\n              width = 0, height = 0.005) +\n  ## add a line for the sample mean\n  geom_vline(xintercept = sample_max, colour = \"red\") +\n  labs(x = \"y\", y = \"density\",\n       title = \"Normal with Mu = 10 and sigma = 2\")\n\n\n\n\n\n\n\n\n#Generating E(Ymin) & E(Ymax) for Normal Dist\n\ngenerate_samp_min &lt;- function(mu, sigma, n) {\n  \n  single_sample &lt;- rnorm(n, mu, sigma)\n  sample_min &lt;- min(single_sample)\n  \n  return(sample_min)\n}\n\n## test function once:\ngenerate_samp_min(mu = mu, sigma = sigma, n = n)\n\n[1] 7.0309\n\nnsim &lt;- 5000      # number of simulations\n\n## code to map through the function. \n## the \\(i) syntax says to just repeat the generate_samp_mean function\n## nsim times\nmins &lt;- map_dbl(1:nsim, \\(i) generate_samp_min(mu = mu, sigma = sigma, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nmins_df &lt;- tibble(mins)\nmins_df\n\n# A tibble: 5,000 × 1\n    mins\n   &lt;dbl&gt;\n 1  6.85\n 2  9.24\n 3  6.74\n 4  5.31\n 5  9.58\n 6  7.65\n 7 10.2 \n 8  7.03\n 9  6.40\n10  7.93\n# ℹ 4,990 more rows\n\nmins_df |&gt;\n  summarise(mean_samp_dist = mean(mins),\n            var_samp_dist = var(mins),\n            sd_samp_dist = sd(mins))\n\n# A tibble: 1 × 3\n  mean_samp_dist var_samp_dist sd_samp_dist\n           &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1           7.67          1.79         1.34\n\n ## E(Ymax)\n\ngenerate_samp_max &lt;- function(mu, sigma, n) {\n  \n  single_sample &lt;- rnorm(n, mu, sigma)\n  sample_max &lt;- max(single_sample)\n  \n  return(sample_max)\n}\n## test function once:\ngenerate_samp_max(mu = mu, sigma = sigma, n = n)\n\n[1] 13.62979\n\nnsim &lt;- 5000      # number of simulations\n\n## code to map through the function. \n## the \\(i) syntax says to just repeat the generate_samp_mean function\n## nsim times\nmaxs &lt;- map_dbl(1:nsim, \\(i) generate_samp_max(mu = mu, sigma = sigma, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nmaxs_df &lt;- tibble(maxs)\nmaxs_df\n\n# A tibble: 5,000 × 1\n    maxs\n   &lt;dbl&gt;\n 1 10.7 \n 2 13.9 \n 3 11.5 \n 4  8.46\n 5 12.5 \n 6 12.1 \n 7 11.3 \n 8  9.93\n 9 11.5 \n10 11.8 \n# ℹ 4,990 more rows\n\nmaxs_df |&gt;\n  summarise(mean_samp_dist = mean(maxs),\n            var_samp_dist = var(maxs),\n            sd_samp_dist = sd(maxs))\n\n# A tibble: 1 × 3\n  mean_samp_dist var_samp_dist sd_samp_dist\n           &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1           12.3          1.85         1.36\n\n\n#Normal Dist. Histograms\n\nggplot(data = mins_df, aes(x = mins)) +\n  geom_histogram(colour = \"darkolivegreen4\", fill = \"darkolivegreen1\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Mins\",\n       title = paste(\"Sampling Distribution of the \\nSample Mins when n =\", n))\n\n\n\n\n\n\n\nggplot(data = maxs_df, aes(x = maxs)) +\n  geom_histogram(colour = \"purple\", fill = \"pink\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Maxs\",\n       title = paste(\"Sampling Distribution of the \\nSample Maxs when n =\", n))\n\n\n\n\n\n\n\n\n#Simulation for Y(min)~Unif(7, 13)\n\nn &lt;- 5       # sample size\ntheta1 &lt;- 7     # non-negative parameter 1\ntheta2 &lt;- 13   # non-negative parameter 2\n\n# generate a random sample of n observations from a Uniform population\nsingle_sample1 &lt;- runif(n, theta1, theta2) |&gt; round(2)\n# look at the sample\nsingle_sample1 \n\n[1] 10.19 10.26  9.73  8.45 12.33\n\n# compute the sample min\nsample_min1 &lt;- min(single_sample1)\n# look at the sample min\nsample_min1   \n\n[1] 8.45\n\n# generate a range of values that span the population\nplot_df1 &lt;- tibble(xvals1 = seq(theta1, theta2, length.out = 500)) |&gt;\n  mutate(xvals_density1 = dunif(xvals1, theta1, theta2))\n\n## plot the population model density curve\nggplot(data = plot_df1, aes(x = xvals1, y = xvals_density1)) +\n  geom_line() +\n  theme_minimal() +\n  ## add the sample points from your sample\n  geom_jitter(data = tibble(single_sample1), aes(x = single_sample1, y = 0),\n              width = 0, height = 0.005) +\n  ## add a line for the sample min\n  geom_vline(xintercept = sample_min1, colour = \"red\") +\n  labs(x = \"y\", y = \"density\",\n       title = \"Uniform with theta1 = 7 and theta2 = 13\")\n\n\n\n\n\n\n\n\n#Simulation for Y(max)~Unif(7, 13)\n\n# compute the sample max\nsample_max1 &lt;- max(single_sample1)\n# look at the sample max\nsample_max1   \n\n[1] 12.33\n\n# generate a range of values that span the population\nplot_df1 &lt;- tibble(xvals1 = seq(theta1, theta2, length.out = 500)) |&gt;\n  mutate(xvals_density1 = dunif(xvals1, theta1, theta2))\n\n## plot the population model density curve\nggplot(data = plot_df1, aes(x = xvals1, y = xvals_density1)) +\n  geom_line() +\n  theme_minimal() +\n  ## add the sample points from your sample\n  geom_jitter(data = tibble(single_sample1), aes(x = single_sample1, y = 0),\n              width = 0, height = 0.005) +\n  ## add a line for the sample max\n  geom_vline(xintercept = sample_max1, colour = \"red\") +\n  labs(x = \"y\", y = \"density\",\n       title = \"Uniform with theta1 = 7 and theta2 = 13\")\n\n\n\n\n\n\n\n\n#Generating E(Ymin) & E(Ymax) for Uniform Distribution\n\ngenerate_samp_min1 &lt;- function(theta1, theta2, n) {\n  \n  single_sample1 &lt;- runif(n, theta1, theta2)\n  sample_min1 &lt;- min(single_sample1)\n  \n  return(sample_min1)\n}\n\n## test function once:\ngenerate_samp_min1(theta1 = theta1, theta2 = theta2, n = n)\n\n[1] 7.665332\n\nnsim &lt;- 5000      # number of simulations\n\n## code to map through the function. \n## the \\(i) syntax says to just repeat the generate_samp_mean function\n## nsim times\nmins1 &lt;- map_dbl(1:nsim, \\(i) generate_samp_min1(theta1 = theta1, theta2 = theta2, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nmins_df1 &lt;- tibble(mins1)\nmins_df1\n\n# A tibble: 5,000 × 1\n   mins1\n   &lt;dbl&gt;\n 1  8.01\n 2  7.87\n 3  7.80\n 4  7.22\n 5  9.20\n 6  8.10\n 7  9.02\n 8  7.89\n 9  7.15\n10  7.79\n# ℹ 4,990 more rows\n\nmins_df1 |&gt;\n  summarise(mean_samp_dist = mean(mins1),\n            var_samp_dist = var(mins1),\n            sd_samp_dist = sd(mins1))\n\n# A tibble: 1 × 3\n  mean_samp_dist var_samp_dist sd_samp_dist\n           &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1           7.98         0.702        0.838\n\n ## E(Ymax)\n\ngenerate_samp_max1 &lt;- function(theta1, theta2, n) {\n  \n  single_sample1 &lt;- runif(n, theta1, theta2)\n  sample_max1 &lt;- max(single_sample1)\n  \n  return(sample_max1)\n}\n\n## test function once:\ngenerate_samp_max1(theta1 = theta1, theta2 = theta2, n = n)\n\n[1] 12.56424\n\nnsim &lt;- 5000      # number of simulations\n\n## code to map through the function. \n## the \\(i) syntax says to just repeat the generate_samp_mean function\n## nsim times\nmaxs1 &lt;- map_dbl(1:nsim, \\(i) generate_samp_max1(theta1 = theta1, theta2 = theta2, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nmaxs_df1 &lt;- tibble(maxs1)\nmaxs_df1\n\n# A tibble: 5,000 × 1\n   maxs1\n   &lt;dbl&gt;\n 1  9.38\n 2 12.8 \n 3 12.9 \n 4 11.5 \n 5 11.8 \n 6 12.1 \n 7 12.7 \n 8 11.3 \n 9 10.3 \n10 12.3 \n# ℹ 4,990 more rows\n\nmaxs_df1 |&gt;\n  summarise(mean_samp_dist = mean(maxs1),\n            var_samp_dist = var(maxs1),\n            sd_samp_dist = sd(maxs1))\n\n# A tibble: 1 × 3\n  mean_samp_dist var_samp_dist sd_samp_dist\n           &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1           12.0         0.730        0.855\n\n\n#Uniform Dist. Histograms\n\nggplot(data = mins_df1, aes(x = mins1)) +\n  geom_histogram(colour = \"darkolivegreen4\", fill = \"darkolivegreen1\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Mins\",\n       title = paste(\"Sampling Distribution of the \\nSample Mins when n =\", n))\n\n\n\n\n\n\n\nggplot(data = maxs_df1, aes(x = maxs1)) +\n  geom_histogram(colour = \"purple\", fill = \"pink\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Maxs\",\n       title = paste(\"Sampling Distribution of the \\nSample Maxs when n =\", n))\n\n\n\n\n\n\n\n\n#Simulation for Y(min)~Exp(lambda = 0.5)\n\nn &lt;- 5       # sample size\nlambda &lt;- 0.5\nmu &lt;- 1 / lambda   # population mean\nsigma &lt;- sqrt(1 / lambda ^ 2)  # population standard deviation\n\n# generate a random sample of n observations from a normal population\nsingle_sample2 &lt;- rexp(n, lambda) |&gt; round(2)\n# look at the sample\nsingle_sample2 \n\n[1] 0.47 6.05 0.98 0.36 1.04\n\n# compute the sample min\nsample_min2 &lt;- min(single_sample2)\n# look at the sample min\nsample_min2 \n\n[1] 0.36\n\n# generate a range of values that span the population\nplot_df2 &lt;- tibble(xvals2 = seq(0, mu + 4 * sigma, length.out = 500)) |&gt;\n  mutate(xvals_density = dexp(xvals2, lambda))\n\n## plot the population model density curve\nggplot(data = plot_df2, aes(x = xvals2, y = xvals_density)) +\n  geom_line() +\n  theme_minimal() +\n  ## add the sample points from your sample\n  geom_jitter(data = tibble(single_sample2), aes(x = single_sample2, y = 0),\n              width = 0, height = 0.005) +\n  ## add a line for the sample min\n  geom_vline(xintercept = sample_min2, colour = \"red\") +\n  labs(x = \"y\", y = \"density\",\n       title = \"Exponential with Lambda = 0.5\")\n\n\n\n\n\n\n\n\n#Simulation for Y(max)~Exp(lambda = 0.5)\n\n# compute the sample max\nsample_max2 &lt;- max(single_sample2)\n# look at the sample max\nsample_max2 \n\n[1] 6.05\n\n# generate a range of values that span the population\nplot_df2 &lt;- tibble(xvals2 = seq(0, mu + 4 * sigma, length.out = 500)) |&gt;\n  mutate(xvals_density = dexp(xvals2, lambda))\n\n## plot the population model density curve\nggplot(data = plot_df2, aes(x = xvals2, y = xvals_density)) +\n  geom_line() +\n  theme_minimal() +\n  ## add the sample points from your sample\n  geom_jitter(data = tibble(single_sample2), aes(x = single_sample2, y = 0),\n              width = 0, height = 0.005) +\n  ## add a line for the sample max\n  geom_vline(xintercept = sample_max2, colour = \"red\") +\n  labs(x = \"y\", y = \"density\",\n       title = \"Exponential with Lambda = 0.5\")\n\n\n\n\n\n\n\n\n#Generating E(Ymin) & E(Ymax) for Exponential Distribution\n\ngenerate_exp_min2 &lt;- function(lambda, n) {\n  \n  single_sample2 &lt;- rexp(n, lambda)\n  sample_min2 &lt;- min(single_sample2)\n  \n  return(sample_min2)\n}\n\n## test function once:\ngenerate_exp_min2(lambda = lambda, n = n)\n\n[1] 0.1351427\n\n#&gt; [1] 3.915946\n\nnsim &lt;- 5000      # number of simulations\n\nmins2 &lt;- map_dbl(1:nsim, \\(i) generate_exp_min2(lambda = lambda, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nmins_df2 &lt;- tibble(mins2)\nmins_df2\n\n# A tibble: 5,000 × 1\n     mins2\n     &lt;dbl&gt;\n 1 0.597  \n 2 0.00459\n 3 0.717  \n 4 0.551  \n 5 0.0879 \n 6 0.271  \n 7 0.0106 \n 8 0.412  \n 9 0.00550\n10 0.756  \n# ℹ 4,990 more rows\n\nmins_df2 |&gt;\n  summarise(min_samp_dist = mean(mins2),\n            var_samp_dist = var(mins2),\n            sd_samp_dist = sd(mins2))\n\n# A tibble: 1 × 3\n  min_samp_dist var_samp_dist sd_samp_dist\n          &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1         0.404         0.166        0.408\n\n ## E(Ymax)\n\ngenerate_exp_max2 &lt;- function(lambda, n) {\n  \n  single_sample2 &lt;- rexp(n, lambda)\n  sample_max2 &lt;- max(single_sample2)\n  \n  return(sample_max2)\n}\n\n## test function once:\ngenerate_exp_max2(lambda = lambda, n = n)\n\n[1] 3.455534\n\n#&gt; [1] 3.915946\n\nnsim &lt;- 5000      # number of simulations\n\nmaxs2 &lt;- map_dbl(1:nsim, \\(i) generate_exp_max2(lambda = lambda, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nmaxs_df2 &lt;- tibble(maxs2)\nmaxs_df2\n\n# A tibble: 5,000 × 1\n   maxs2\n   &lt;dbl&gt;\n 1  3.68\n 2  1.42\n 3  3.60\n 4  5.43\n 5  5.30\n 6  4.68\n 7  2.56\n 8  3.13\n 9  2.14\n10  4.47\n# ℹ 4,990 more rows\n\nmaxs_df2 |&gt;\n  summarise(max_samp_dist = mean(maxs2),\n            var_samp_dist = var(maxs2),\n            sd_samp_dist = sd(maxs2))\n\n# A tibble: 1 × 3\n  max_samp_dist var_samp_dist sd_samp_dist\n          &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1          4.54          5.76         2.40\n\n\n#Exponential Dist. Histograms\n\nggplot(data = mins_df2, aes(x = mins2)) +\n  geom_histogram(colour = \"darkolivegreen4\", fill = \"darkolivegreen1\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Mins\",\n       title = paste(\"Sampling Distribution of the \\nSample Mins when n =\", n))\n\n\n\n\n\n\n\nggplot(data = maxs_df2, aes(x = maxs2)) +\n  geom_histogram(colour = \"purple\", fill = \"pink\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Maxs\",\n       title = paste(\"Sampling Distribution of the \\nSample Maxs when n =\", n))\n\n\n\n\n\n\n\n\n#Simulation for Y(min)~Beta(alpha = 8, beta = 2)\n\nn &lt;- 5       # sample size\nalpha &lt;- 8     \nbeta &lt;- 2   \n\n# generate a random sample of n observations from a normal population\nsingle_sample3 &lt;- rbeta(n, alpha, beta) |&gt; round(2)\n# look at the sample\nsingle_sample3 \n\n[1] 0.71 0.93 0.77 0.82 0.82\n\n# compute the sample mean\nsample_min3 &lt;- min(single_sample3)\n# look at the sample mean\nsample_min3  \n\n[1] 0.71\n\n\n#Simulation for Y(max)~Beta(alpha = 8, beta = 2)\n\n# compute the sample mean\nsample_max3 &lt;- max(single_sample3)\n# look at the sample mean\nsample_max3  \n\n[1] 0.93\n\n\n#Generating E(Ymin) & E(Ymax) for Beta Distribution\n\ngenerate_sample_min3 &lt;- function(alpha, beta, n) {\n  \n  single_sample3 &lt;- rbeta(n, alpha, beta)\n  sample_min3 &lt;- min(single_sample3)\n  \n  return(sample_min3)\n}\n\n## test function once:\ngenerate_sample_min3(alpha = alpha, beta = beta, n = n)\n\n[1] 0.5883812\n\n#&gt; [1] 3.915946\n\nnsim &lt;- 5000      # number of simulations\n\nmins3 &lt;- map_dbl(1:nsim, \\(i) generate_sample_min3(alpha = alpha, beta = beta, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nmins_df3 &lt;- tibble(mins3)\nmins_df3\n\n# A tibble: 5,000 × 1\n   mins3\n   &lt;dbl&gt;\n 1 0.778\n 2 0.588\n 3 0.636\n 4 0.719\n 5 0.604\n 6 0.591\n 7 0.664\n 8 0.634\n 9 0.689\n10 0.601\n# ℹ 4,990 more rows\n\nmins_df3 |&gt;\n  summarise(mean_samp_dist = mean(mins3),\n            var_samp_dist = var(mins3),\n            sd_samp_dist = sd(mins3))\n\n# A tibble: 1 × 3\n  mean_samp_dist var_samp_dist sd_samp_dist\n           &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1          0.648        0.0111        0.105\n\n ## E(Ymax)\n\ngenerate_sample_max3 &lt;- function(alpha, beta, n) {\n  \n  single_sample3 &lt;- rbeta(n, alpha, beta)\n  sample_max3 &lt;- max(single_sample3)\n  \n  return(sample_max3)\n}\n\n## test function once:\ngenerate_sample_max3(alpha = alpha, beta = beta, n = n)\n\n[1] 0.9220206\n\n#&gt; [1] 3.915946\n\nnsim &lt;- 5000      # number of simulations\n\nmaxs3 &lt;- map_dbl(1:nsim, \\(i) generate_sample_max3(alpha = alpha, beta = beta, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nmaxs_df3 &lt;- tibble(maxs3)\nmaxs_df3\n\n# A tibble: 5,000 × 1\n   maxs3\n   &lt;dbl&gt;\n 1 0.901\n 2 0.959\n 3 0.871\n 4 0.986\n 5 0.960\n 6 0.979\n 7 0.910\n 8 0.911\n 9 0.929\n10 0.977\n# ℹ 4,990 more rows\n\nmaxs_df3 |&gt;\n  summarise(mean_samp_dist = mean(maxs3),\n            var_samp_dist = var(maxs3),\n            sd_samp_dist = sd(maxs3))\n\n# A tibble: 1 × 3\n  mean_samp_dist var_samp_dist sd_samp_dist\n           &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1          0.922       0.00215       0.0464\n\n\n#Beta Dist. Histograms\n\nggplot(data = mins_df3, aes(x = mins3)) +\n  geom_histogram(colour = \"darkolivegreen4\", fill = \"darkolivegreen1\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Mins\",\n       title = paste(\"Sampling Distribution of the \\nSample Mins when n =\", n))\n\n\n\n\n\n\n\nggplot(data = maxs_df3, aes(x = maxs3)) +\n  geom_histogram(colour = \"purple\", fill = \"pink\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Maxs\",\n       title = paste(\"Sampling Distribution of the \\nSample Maxs when n =\", n))\n\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\n## create population graphs\n\nnorm_df &lt;- tibble(x = seq(3, 17, length.out = 1000),\n                  dens = dnorm(x, mean = 10, sd = 2),\n                  pop = \"normal(10, 4)\")\nunif_df &lt;- tibble(x = seq(7, 13, length.out = 1000),\n                  dens = dunif(x, 7, 13),\n                  pop = \"uniform(7, 13)\")\nexp_df &lt;- tibble(x = seq(0, 10, length.out = 1000),\n                 dens = dexp(x, 0.5),\n                 pop = \"exp(0.5)\")\nbeta_df &lt;- tibble(x = seq(0, 1, length.out = 1000),\n                  dens = dbeta(x, 8, 2),\n                  pop = \"beta(8, 2)\")\n\npop_plot &lt;- bind_rows(norm_df, unif_df, exp_df, beta_df) |&gt;\n  mutate(pop = fct_relevel(pop, c(\"normal(10, 4)\", \"uniform(7, 13)\",\n                                  \"exp(0.5)\", \"beta(8, 2)\")))\n\nggplot(data = pop_plot, aes(x = x, y = dens)) +\n  geom_line() +\n  theme_minimal() +\n  facet_wrap(~ pop, nrow = 1, scales = \"free\") +\n  geom_vline(  #geom_vline() to create vertical line for minimum\n    data = filter(pop_plot, pop == \"normal(10, 4)\"), #filter through pop_plot for normal dist ONLY\n    aes(xintercept = sample_min),\n    color = \"red\"\n  ) +\n  geom_vline(\n    data = filter(pop_plot, pop == \"uniform(7, 13)\"),\n    aes(xintercept = sample_min1),\n    color = \"red\"\n  ) +\n  geom_vline(\n    data = filter(pop_plot, pop == \"exp(0.5)\"),\n    aes(xintercept = sample_min2),\n    color = \"red\"\n  ) +\n  geom_vline(\n    data = filter(pop_plot, pop == \"beta(8, 2)\"),  #filter through pop_plot for beta dist ONLY\n    aes(xintercept = sample_min3),\n    color = \"red\"\n  ) +\n  labs(title = \"Population Distributions for Each Simulation Setting\")\n\n\n\n\n\n\n\n\n\npop_plot &lt;- bind_rows(norm_df, unif_df, exp_df, beta_df) |&gt;\n  mutate(pop = fct_relevel(pop, c(\"normal(10, 4)\", \"uniform(7, 13)\",\n                                  \"exp(0.5)\", \"beta(8, 2)\")))\n\nggplot(data = pop_plot, aes(x = x, y = dens)) +\n  geom_line() +\n  theme_minimal() +\n  facet_wrap(~ pop, nrow = 1, scales = \"free\") +\n  geom_vline(  #geom_vline() to create vertical line for maximum now\n    data = filter(pop_plot, pop == \"normal(10, 4)\"), #filter through pop_plot for normal dist ONLY\n    aes(xintercept = sample_max),\n    color = \"red\"\n  ) +\n  geom_vline(\n    data = filter(pop_plot, pop == \"uniform(7, 13)\"),\n    aes(xintercept = sample_max1),\n    color = \"red\"\n  ) +\n  geom_vline(\n    data = filter(pop_plot, pop == \"exp(0.5)\"),\n    aes(xintercept = sample_max2),\n    color = \"red\"\n  ) +\n  geom_vline(\n    data = filter(pop_plot, pop == \"beta(8, 2)\"),  #filter through pop_plot for beta dist ONLY\n    aes(xintercept = sample_max3),\n    color = \"red\"\n  ) +\n  labs(title = \"Population Distributions for Each Simulation Setting\")\n\n\n\n\n\n\n\n\n\nTable of Results\n\n\n\n\n\n\n\n\n\n\n\\(\\text{N}(\\mu = 10, \\sigma^2 = 4)\\)\n\\(\\text{Unif}(\\theta_1 = 7, \\theta_2 = 13)\\)\n\\(\\text{Exp}(\\lambda = 0.5)\\)\n\\(\\text{Beta}(\\alpha = 8, \\beta = 2)\\)\n\n\n\n\n\\(\\text{E}(Y_{min})\\)\n7.669958\n7.991146\n0.4051406\n0.6482102\n\n\n\\(\\text{E}(Y_{max})\\)\n12.33767\n12.00729\n4.538364\n0.9214295\n\n\n\n\n\n\n\n\n\n\\(\\text{SE}(Y_{min})\\)\n1.333249\n0.8342634\n0.4029039\n0.1051907\n\n\n\\(\\text{SE}(Y_{max})\\)\n1.337612\n0.8492786\n2.416008\n0.04662133\n\n\n\n\nBriefly summarise how SE(Ymin) and SE(Ymax) compare for each of the above population models. Can you propose a general rule or result for how SE(Ymin) and SE(Ymax) compare for a given population?\n\nSE(Ymin) and SE(Ymax) in the Normal Distribution are the same and SE(Ymin) and SE(Ymax) for the Uniform Distribution are also the same. The standard errors are roughly symmetrical and this makes sense because the density plots of these two distributions for minimum and maximum behave symmetrical as well. For the Exponential and Beta Distributions, SE(Ymin) and SE(Ymax) are not the same or similar. It seems that in these distributions, because they are skewed both to the right and this causes more variability in standard error of the distributions. A general rule for how SE(Ymin) and SE(Ymax) compare for a given population might be if the population density is symmetrical, the Standard Errors of the maximum and minimum will be very close if not the same, and for skewed or asymmetrical population density, the maximum and minimum will have more variability causing the standard errors to most likely not match up.\n\nChoose either the third (Exponential) or fourth (Beta) population model from the table above. For that population model, find the pdf of Ymin⁡ and Ymax, and, for each of those random variables, sketch the pdfs and use integration to calculate the expected value and standard error. What do you notice about how your answers compare to the simulated answers? Some code is given below to help you plot the pdfs in R:\n\nThe answers I got from my hand calculations match up with the simulation calculations for E(Ymin) and E(Ymax) as well as the standard errors!\n\nn &lt;- 5\n## CHANGE 0 and 3 to represent where you want your graph to start and end\n## on the x-axis\nx &lt;- seq(0, 3, length.out = 1000)\n## CHANGE to be the pdf you calculated. Note that, as of now, \n## this is not a proper density (it does not integrate to 1).\ndensity &lt;- n * (-exp(-(0.5) * x))^4 * 0.5*exp(-0.5 *x)\n\n\n## put into tibble and plot\nsamp_min_df &lt;- tibble(x, density)\nggplot(data = samp_min_df, aes(x = x, y = density)) +\n  geom_line() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nn &lt;- 5\n## CHANGE 0 and 3 to represent where you want your graph to start and end\n## on the x-axis\nx1 &lt;- seq(0, 3, length.out = 1000)\n## CHANGE to be the pdf you calculated. Note that, as of now, \n## this is not a proper density (it does not integrate to 1).\ndensity1 &lt;- n * (1-exp(-0.5 * x1))^4 * 0.5*exp(-0.5 *x1)\n\n\n## put into tibble and plot\nsamp_max_df &lt;- tibble(x, density1)\nggplot(data = samp_max_df, aes(x = x, y = density1)) +\n  geom_line() +\n  theme_minimal()"
  },
  {
    "objectID": "posts/02-meaningful_story/index.html",
    "href": "posts/02-meaningful_story/index.html",
    "title": "Mini Project 2",
    "section": "",
    "text": "A day in the life of townhouse 204\nTownhouse 204 is a wonderful inviting home on the outskirts of campus, kitty-cornered with B-lot and the golf course. I live in this house with 5 of my bestest friends from freshman year, Cara, Nina, Lyv, Darcie and Mo. We have a very creative and different major oriented household, with all of us studying in a different field that leads us to come up with quirky things and activities to do all the time. For example we just built an igloo around our back porch to enjoy these recently sunny rays without having to get blown over by the wind.\nSince the beginning of the semester, we have started collecting can tabs (from our sparkling waters of course) and putting them all on a string that hangs on our wall to see how many we reach by the end of the semester. At about halfway down the string, we counted the can tabs, but now there are way too many tabs collected to sit and count manually. With less than 100 days left of our St. Lawrence career we are all left asking, how many tabs will we have by the end of the semester? Of course, me being a stats major I realized we can use an estimator to calculate an estimate of the final number of tabs we will have!\nThe total number of can tabs we have at the end of the semester is currently a mystery, or an unknown parameter. Since we know we do not want to count them all by hand (which we eventually will to get an exact number), I offered using some of my stat 326 skills to come up with the best estimate for this. At the beginning of the semester, we would count the collected can tabs occasionally, from 20 to 50 to sometimes a low number like 10, representing a random variable that changed by week. I offered maybe using a random sample from the few times we counted the can tabs to estimate what our final number would be. Darcie however, piped up and said, “But guys, wait! We could’ve been extra thirsty and focused on hydrating on some weeks where we counted, or the opposite, studying during finals and had less time to crack open a cold water”. I realized that Darcie was implying that we may have bias in our sample and commended her on thinking about this. It is true, it will be biased by count, but as well if we just simply forget to count what we collected in some weeks. Once I explained bias to them, Lyv pointed out another thing we didn’t keep in mind. Lyv points out that from week to week when we were still able to count the collected tabs, the numbers varied a lot and did not go up at a consistent rate from what we counted the week before. Some weeks our count would be 15 tabs, but other weeks it would be close to 50! This triggered my brain to realize that our estimate is fluctuating because of the variance between weeks of collecting and counting. I offered up another solution to this. If we continue to collect and count our tabs consistently throughout the remainder of the semester, over time our estimate should become more accurate. At this point, Mo had had enough of this statistics gibber gabber, and exclaims, “What’s the likelihood that we reach 1000 can tabs by finals week, I don’t care about all these calculations”! This made me laugh, because without even meaning it she asked a statistical question that could be solved.\nOnce I explained to Mo that it is actually faster to use an estimator for this than counting the can tabs, she was on board. Nina and Cara were lost and starting to lose hope, but I finally figured out the best solution for this madness. If we collect tabs over time, our weekly count of the collected can tabs could follow a Poisson distribution. If we estimate the average number of tabs we collect weekly by the end of finals week, we can use this distribution to predict the likelihood that we get to 1000 tabs like Mo said!\nThe ladies of townhouse 204 have been coming together and counting our collected tabs weekly, in hopes to get an estimate for the likelihood soon.\n“All work presented is my own, and I have followed all rules for collaboration. I have not used generative AI on this project.”"
  },
  {
    "objectID": "posts/04-bayesian/index.html",
    "href": "posts/04-bayesian/index.html",
    "title": "Mini Project 4",
    "section": "",
    "text": "“I have followed all rules for collaboration for this project, and I have not used generative AI on this project.”\nThe question of interest for this project is can we predict the probability that Nadal wins a point on his own serve against his primary rival, Novak Djokovic, at the French Open (the most prestigious clay court tournament in the world). We will answer this by using 3 different priors, a noninformative, and two informative priors based on preexisting knowledge or not. We will then update our posterior distributions to take into account the 2020 French open to get a more accurate estimate at the end, finishing off the project with 3 different credible posterior intervals with 90% confidence.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nps &lt;- seq(0, 1, length.out = 1000)\n\nnoninformative_alpha &lt;- 1\nnoninformative_beta &lt;- 1\n\nnoninformative_prior &lt;- dbeta(ps,\n                              noninformative_alpha, noninformative_beta)\n\nThe fist prior is completely non-informative. This means we have no preexisting knowledge of Nadal’s performance or any idea of how it will go, so we will use a Beta(1, 1), which is equal to Uniform(0, 1) where 0 represents a loss and 1 represents a win on a serve. Uniform(0,1) assigns the same probability for every value in the interval, not making any assumptions about the points won on Nadal’s serves.\n\ntarget_mean &lt;- 0.697\n\nalphas &lt;- seq(0.1, 100, length.out = 500)\nbetas &lt;- 0.303 * alphas / 0.697\n\nparam_df &lt;- tibble(alphas, betas)\nparam_df &lt;- param_df |&gt; mutate(vars = \n                    (alphas * betas) / ((alphas + betas)^2 * (alphas + betas + 1)))\n\n\ntarget_var &lt;- 0.05657 ^2\n\nparam_df &lt;- param_df |&gt; mutate(dist_to_target = abs(vars - target_var))\nparam_df\n\n# A tibble: 500 × 4\n   alphas  betas   vars dist_to_target\n    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;          &lt;dbl&gt;\n 1  0.1   0.0435 0.185          0.181 \n 2  0.300 0.131  0.148          0.144 \n 3  0.500 0.218  0.123          0.120 \n 4  0.701 0.305  0.105          0.102 \n 5  0.901 0.392  0.0921         0.0889\n 6  1.10  0.479  0.0819         0.0787\n 7  1.30  0.566  0.0737         0.0705\n 8  1.50  0.653  0.0670         0.0638\n 9  1.70  0.740  0.0614         0.0582\n10  1.90  0.827  0.0566         0.0534\n# ℹ 490 more rows\n\nparam_df |&gt; filter(dist_to_target == min(dist_to_target))\n\n# A tibble: 1 × 4\n  alphas betas    vars dist_to_target\n   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;          &lt;dbl&gt;\n1   45.3  19.7 0.00320     0.00000310\n\ninformative_alpha &lt;- 45.345\ninformative_beta &lt;- 19.713\n\nFor the second prior, it is informative based on a clay-court match the two played in the previous year. In that match, Nadal won 46 out of 66 points on his own serve. The standard error of this estimate is 0.05657. Again, I chose a beta distribution but to find the alphas and betas I worked backwards from the mean equation for a beta distribution (E(x) = alpha/alpha+beta). Once I found Beta = (0.303 * alpha)/0.697, I assigned a sequence of values for alpha and used this formula to solve for beta. In addition to this, I also incorporated the standard error into a target variance, by squaring it and made sure the parameters were adjusted accordingly.\n\ntarget_mean &lt;- 0.75\n\nalphas &lt;- seq(0.1, 100, length.out = 500)\nbetas &lt;- 0.25 * alphas / 0.75\n\nparam_df &lt;- tibble(alphas, betas)\nparam_df &lt;- param_df |&gt; mutate(vars = \n                    (alphas * betas) / ((alphas + betas)^2 * (alphas + betas + 1)))\n\n\ntarget_var &lt;- 0.05 ^2\n\nparam_df &lt;- param_df |&gt; mutate(dist_to_target = abs(vars - target_var))\nparam_df\n\n# A tibble: 500 × 4\n   alphas  betas   vars dist_to_target\n    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;          &lt;dbl&gt;\n 1  0.1   0.0333 0.165          0.163 \n 2  0.300 0.100  0.134          0.131 \n 3  0.500 0.167  0.112          0.110 \n 4  0.701 0.234  0.0969         0.0944\n 5  0.901 0.300  0.0852         0.0827\n 6  1.10  0.367  0.0760         0.0735\n 7  1.30  0.434  0.0686         0.0661\n 8  1.50  0.500  0.0625         0.0600\n 9  1.70  0.567  0.0574         0.0549\n10  1.90  0.634  0.0530         0.0505\n# ℹ 490 more rows\n\nparam_df |&gt; filter(dist_to_target == min(dist_to_target))\n\n# A tibble: 1 × 4\n  alphas betas    vars dist_to_target\n   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;          &lt;dbl&gt;\n1   55.6  18.5 0.00250     0.00000246\n\ninformative_alpha2 &lt;- 55.555\ninformative_beta2 &lt;- 18.519\n\nFor the third prior, it is another informative one based on a sports announcer, who claims that they think Nadal wins about 75% of the points on his serve against Djokovic. They are also “almost sure” that Nadal wins no less than 70% of his points on serve against Djokovic. To figure out this final prior, I used the same strategy for the second prior with a little bit different logic. For this prior it will be another Beta, and we have once again been given the proportion of wins and can work backwards with the mean formula to get the betas = (0.25 * alphas) / 0.75. To make sure that this mean does not go below 70%, I chose a standard error of 0.05 and proceeded with the same strategy as the first prior.\n\ninformative_prior &lt;- dbeta(ps, informative_alpha,\n                           informative_beta)\ninformative_prior2 &lt;- dbeta(ps, informative_alpha2,\n                           informative_beta2)\n\nnoninformative_prior &lt;- dbeta(ps,\n                              noninformative_alpha, noninformative_beta)\n\n\nprior_plot &lt;- tibble(ps, informative_prior, noninformative_prior, informative_prior2) |&gt;\n  pivot_longer(2:4, names_to = \"prior_type\", values_to = \"density\")\n\nggplot(data = prior_plot, aes(x = ps, y = density, colour = prior_type)) +\n  geom_line() +\n  scale_colour_viridis_d(end = 0.9) +\n  theme_minimal() +\n  labs(x = \"p\")\n\n\n\n\n\n\n\n\n\ninformative_alpha_post &lt;- informative_alpha + 56\ninformative_beta_post &lt;- informative_beta + (84 - 56)\ninformative_post &lt;- dbeta(ps, informative_alpha_post,\n                          informative_beta_post)\n\n#posterior mean for 2nd prior\ninformative_alpha_post / (informative_alpha_post + informative_beta_post)\n\n[1] 0.6799031\n\ninformative_alpha_post2 &lt;- informative_alpha2 + 56\ninformative_beta_post2 &lt;- informative_beta2 + (84 - 56)\ninformative_post2 &lt;- dbeta(ps, informative_alpha_post2,\n                          informative_beta_post2)\n#posterior mean for 3rd prior\ninformative_alpha_post2 / (informative_alpha_post2 + informative_beta_post2)\n\n[1] 0.7057138\n\n## CHANGE THESE\nnoninformative_alpha_post &lt;- noninformative_alpha + 56\nnoninformative_beta_post &lt;- noninformative_beta + (84 - 56)\nnoninformative_post &lt;- dbeta(ps, noninformative_alpha_post,\n                             noninformative_beta_post)\n#posterior mean for noninformative prior\nnoninformative_alpha_post / (noninformative_alpha_post + noninformative_beta_post)\n\n[1] 0.6627907\n\nplot_df &lt;- tibble(ps,\n                     informative_post, noninformative_post, informative_post2) |&gt;\n  pivot_longer(2:4, names_to = \"distribution\", values_to = \"density\")\n\nggplot(data = plot_df, aes(x = ps, y = density, colour = distribution)) +\n  geom_line() +\n  scale_colour_viridis_d(end = 0.9) +\n  theme_minimal() +\n  labs(x = \"p\")\n\n\n\n\n\n\n\n\nCredible Intervals\n\nnoninformative_post_int &lt;- qbeta(c(0.05, 0.95), 57, 29)\n\ninformative_post_int &lt;- qbeta(c(0.05, 0.95), informative_alpha + 56, informative_beta + (84 - 56))\n\ninformative_post_int2 &lt;- qbeta(c(0.05, 0.95), informative_alpha2 + 56, informative_beta2 + (84 - 56))\n\nThe three posteriors that I ended up with were all a little different from eachother. The noninformative prior gave the lowest posterior mean of 0.66279, followed by the posterior mean for the prior based on the previous year at 0.6768, then finally the highest mean of 0.6799 belongs to the prior based on the announcers estimate. They are all different from eachother slightly because of the information we used to obtain the priors. The non-informative prior is the closest to the actual mean from 2020, 0.6667. The variance of the non informative prior is the highest based on the plot of the posterior distributions. Between the two informative posteriors, the one based on the announcer’s prediction has a very slightly lower variance than the one based on data from the previous year, yet this is barely noticeable and at the end of the day they look like they have almost exactly the same variance. If I had to choose one posterior to rely on, I would choose the one based on the previous year’s data. There is too much variance within the non-informative posterior. Because the variances for the two informative posteriors are so similar, I won’t take that very strongly into consideration. Between the two, the one based on the previous years data has a posterior mean closer to the 2020 match, and I would pick that one.\nIn conclusion, I found that using an informative prior in this case helps make the estimates closer to the actual win percentage with a lower variance. There is a lot more variabliity in a non informative prior because you are assuming there is no difference between players skill level, which is never the case in these scenarios."
  },
  {
    "objectID": "posts/03-confidence_intervals/index.html",
    "href": "posts/03-confidence_intervals/index.html",
    "title": "Mini Project 3",
    "section": "",
    "text": "library(resample)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n“I have followed all rules for collaboration for this project, and I have not used generative AI on this project.”"
  },
  {
    "objectID": "posts/03-confidence_intervals/index.html#setting-1-n-1000-p-0.45",
    "href": "posts/03-confidence_intervals/index.html#setting-1-n-1000-p-0.45",
    "title": "Mini Project 3",
    "section": "Setting 1: n = 1000, p = 0.45",
    "text": "Setting 1: n = 1000, p = 0.45\n\nn1 &lt;- 1000   # sample size\np1 &lt;- 0.45  # population proportion\n  \n\ngenerate_samp_prop &lt;-function(n, p) {\n  x &lt;- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat &lt;- x / n\n  \n  ## 90% confidence interval\n  lb &lt;- phat - 1.645 * sqrt(phat * (1 - phat) / n)\n  ub &lt;- phat + 1.645 * sqrt(phat * (1 - phat) / n)\n  \n  prop_df &lt;- tibble(phat, lb, ub)\n  return(prop_df)\n}\n\ngenerate_samp_prop(n = 1000, p = 0.45)\n\n# A tibble: 1 × 3\n   phat    lb    ub\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 0.434 0.408 0.460\n\n## how many CI's do we want\nn_sim &lt;- 5000\n\nprop_ci_df &lt;- map(1:n_sim, \n    \\(i) generate_samp_prop(n = 1000, p = 0.45)) |&gt;\n  bind_rows()\n\nprop_ci_df\n\n# A tibble: 5,000 × 3\n    phat    lb    ub\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 0.445 0.419 0.471\n 2 0.473 0.447 0.499\n 3 0.429 0.403 0.455\n 4 0.437 0.411 0.463\n 5 0.461 0.435 0.487\n 6 0.449 0.423 0.475\n 7 0.466 0.440 0.492\n 8 0.451 0.425 0.477\n 9 0.442 0.416 0.468\n10 0.468 0.442 0.494\n# ℹ 4,990 more rows\n\n\nAverage interval width and coverage rate\n\nprop_ci_df &lt;- prop_ci_df |&gt; mutate(ci_width = ub - lb,\n                     ci_cover_ind = if_else(p1 &gt; lb & p1 &lt; ub,\n                                            true = 1,\n                                            false = 0))\nprop_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1    0.0517         0.903"
  },
  {
    "objectID": "posts/03-confidence_intervals/index.html#setting-2-n-1000-p-.90",
    "href": "posts/03-confidence_intervals/index.html#setting-2-n-1000-p-.90",
    "title": "Mini Project 3",
    "section": "Setting 2: n = 1000, p = .90",
    "text": "Setting 2: n = 1000, p = .90\n\nn1 &lt;- 1000   # sample size\np2 &lt;- 0.9  # population proportion\n  \n\ngenerate_samp_prop &lt;-function(n, p) {\n  x &lt;- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat &lt;- x / n\n  \n  ## 90% confidence interval\n  lb &lt;- phat - 1.645 * sqrt(phat * (1 - phat) / n)\n  ub &lt;- phat + 1.645 * sqrt(phat * (1 - phat) / n)\n  \n  prop_df &lt;- tibble(phat, lb, ub)\n  return(prop_df)\n}\n\ngenerate_samp_prop(n = 1000, p = 0.9)\n\n# A tibble: 1 × 3\n   phat    lb    ub\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 0.893 0.877 0.909\n\n## how many CI's do we want\nn_sim &lt;- 5000\n\nprop_ci_df1 &lt;- map(1:n_sim, \n    \\(i) generate_samp_prop(n = 1000, p = 0.9)) |&gt;\n  bind_rows()\n\nprop_ci_df1\n\n# A tibble: 5,000 × 3\n    phat    lb    ub\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 0.889 0.873 0.905\n 2 0.882 0.865 0.899\n 3 0.904 0.889 0.919\n 4 0.894 0.878 0.910\n 5 0.901 0.885 0.917\n 6 0.9   0.884 0.916\n 7 0.899 0.883 0.915\n 8 0.884 0.867 0.901\n 9 0.899 0.883 0.915\n10 0.896 0.880 0.912\n# ℹ 4,990 more rows\n\n\nAverage interval width and coverage rate\n\nprop_ci_df1 &lt;- prop_ci_df1 |&gt; mutate(ci_width = ub - lb,\n                   ci_cover_ind = if_else(p2 &gt; lb & p2 &lt; ub,\n                                          true = 1,\n                                          false = 0))\nprop_ci_df1 |&gt; summarise(avg_width = mean(ci_width),\n                      coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1    0.0312         0.889"
  },
  {
    "objectID": "posts/03-confidence_intervals/index.html#setting-3-n-100-p-.45",
    "href": "posts/03-confidence_intervals/index.html#setting-3-n-100-p-.45",
    "title": "Mini Project 3",
    "section": "Setting 3: n = 100, p = .45",
    "text": "Setting 3: n = 100, p = .45\n\nn2 &lt;- 100   # sample size\np1 &lt;- 0.45  # population proportion\n  \n\ngenerate_samp_prop &lt;-function(n, p) {\n  x &lt;- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat &lt;- x / n\n  \n  ## 90% confidence interval\n  lb &lt;- phat - 1.645 * sqrt(phat * (1 - phat) / n)\n  ub &lt;- phat + 1.645 * sqrt(phat * (1 - phat) / n)\n  \n  prop_df &lt;- tibble(phat, lb, ub)\n  return(prop_df)\n}\n\ngenerate_samp_prop(n = 100, p = 0.45)\n\n# A tibble: 1 × 3\n   phat    lb    ub\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1   0.5 0.418 0.582\n\n## how many CI's do we want\nn_sim &lt;- 5000\n\nprop_ci_df2 &lt;- map(1:n_sim, \n    \\(i) generate_samp_prop(n = 100, p = 0.45)) |&gt;\n  bind_rows()\n\nprop_ci_df2\n\n# A tibble: 5,000 × 3\n    phat    lb    ub\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.46 0.378 0.542\n 2  0.48 0.398 0.562\n 3  0.39 0.310 0.470\n 4  0.38 0.300 0.460\n 5  0.41 0.329 0.491\n 6  0.48 0.398 0.562\n 7  0.4  0.319 0.481\n 8  0.45 0.368 0.532\n 9  0.47 0.388 0.552\n10  0.44 0.358 0.522\n# ℹ 4,990 more rows\n\n\nAverage interval width and coverage rate\n\nprop_ci_df2 &lt;- prop_ci_df2 |&gt; mutate(ci_width = ub - lb,\n                   ci_cover_ind = if_else(p1 &gt; lb & p1 &lt; ub,\n                                          true = 1,\n                                          false = 0))\nprop_ci_df2 |&gt; summarise(avg_width = mean(ci_width),\n                      coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.163         0.888"
  },
  {
    "objectID": "posts/03-confidence_intervals/index.html#setting-4-n-100-p-0.9",
    "href": "posts/03-confidence_intervals/index.html#setting-4-n-100-p-0.9",
    "title": "Mini Project 3",
    "section": "Setting 4: n = 100, p = 0.9",
    "text": "Setting 4: n = 100, p = 0.9\n\nn2 &lt;- 100   # sample size\np2 &lt;- 0.9  # population proportion\n  \n\ngenerate_samp_prop &lt;-function(n, p) {\n  x &lt;- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat &lt;- x / n\n  \n  ## 90% confidence interval\n  lb &lt;- phat - 1.645 * sqrt(phat * (1 - phat) / n)\n  ub &lt;- phat + 1.645 * sqrt(phat * (1 - phat) / n)\n  \n  prop_df &lt;- tibble(phat, lb, ub)\n  return(prop_df)\n}\n\ngenerate_samp_prop(n = 100, p = 0.9)\n\n# A tibble: 1 × 3\n   phat    lb    ub\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  0.89 0.839 0.941\n\n## how many CI's do we want\nn_sim &lt;- 5000\n\nprop_ci_df3 &lt;- map(1:n_sim, \n    \\(i) generate_samp_prop(n = 100, p = 0.9)) |&gt;\n  bind_rows()\n\nprop_ci_df3\n\n# A tibble: 5,000 × 3\n    phat    lb    ub\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.84 0.780 0.900\n 2  0.89 0.839 0.941\n 3  0.91 0.863 0.957\n 4  0.92 0.875 0.965\n 5  0.89 0.839 0.941\n 6  0.86 0.803 0.917\n 7  0.93 0.888 0.972\n 8  0.88 0.827 0.933\n 9  0.89 0.839 0.941\n10  0.92 0.875 0.965\n# ℹ 4,990 more rows\n\n\nAverage interval width and coverage rate\n\nprop_ci_df3 &lt;- prop_ci_df3 |&gt; mutate(ci_width = ub - lb,\n                   ci_cover_ind = if_else(p2 &gt; lb & p2 &lt; ub,\n                                          true = 1,\n                                          false = 0))\nprop_ci_df3 |&gt; summarise(avg_width = mean(ci_width),\n                      coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1    0.0973         0.866"
  },
  {
    "objectID": "posts/03-confidence_intervals/index.html#setting-5-n-10-p-0.45",
    "href": "posts/03-confidence_intervals/index.html#setting-5-n-10-p-0.45",
    "title": "Mini Project 3",
    "section": "Setting 5: n = 10, p = 0.45",
    "text": "Setting 5: n = 10, p = 0.45\n\nn3 &lt;- 10   # sample size\np1 &lt;- 0.45  # population proportion\n  \n\ngenerate_samp_prop &lt;-function(n, p) {\n  x &lt;- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat &lt;- x / n\n  \n  ## 90% confidence interval\n  lb &lt;- phat - 1.645 * sqrt(phat * (1 - phat) / n)\n  ub &lt;- phat + 1.645 * sqrt(phat * (1 - phat) / n)\n  \n  prop_df &lt;- tibble(phat, lb, ub)\n  return(prop_df)\n}\n\ngenerate_samp_prop(n = 10, p = 0.45)\n\n# A tibble: 1 × 3\n   phat    lb    ub\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1   0.5 0.240 0.760\n\n## how many CI's do we want\nn_sim &lt;- 5000\n\nprop_ci_df4 &lt;- map(1:n_sim, \n    \\(i) generate_samp_prop(n = 10, p = 0.45)) |&gt;\n  bind_rows()\n\nprop_ci_df4\n\n# A tibble: 5,000 × 3\n    phat       lb    ub\n   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1   0.2 -0.00808 0.408\n 2   0.4  0.145   0.655\n 3   0.3  0.0616  0.538\n 4   0.5  0.240   0.760\n 5   0.4  0.145   0.655\n 6   0.4  0.145   0.655\n 7   0.5  0.240   0.760\n 8   0.6  0.345   0.855\n 9   0.5  0.240   0.760\n10   0.4  0.145   0.655\n# ℹ 4,990 more rows\n\n\nAverage interval width and coverage rate\n\nprop_ci_df4 &lt;- prop_ci_df4 |&gt; mutate(ci_width = ub - lb,\n                   ci_cover_ind = if_else(p1 &gt; lb & p1 &lt; ub,\n                                          true = 1,\n                                          false = 0))\nprop_ci_df4 |&gt; summarise(avg_width = mean(ci_width),\n                      coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.489         0.805"
  },
  {
    "objectID": "posts/03-confidence_intervals/index.html#seting-6-n-10-p-0.9",
    "href": "posts/03-confidence_intervals/index.html#seting-6-n-10-p-0.9",
    "title": "Mini Project 3",
    "section": "Seting 6: n = 10, p = 0.9",
    "text": "Seting 6: n = 10, p = 0.9\n\nn3 &lt;- 10   # sample size\np2 &lt;- 0.9  # population proportion\n  \n\ngenerate_samp_prop &lt;-function(n, p) {\n  x &lt;- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat &lt;- x / n\n  \n  ## 90% confidence interval\n  lb &lt;- phat - 1.645 * sqrt(phat * (1 - phat) / n)\n  ub &lt;- phat + 1.645 * sqrt(phat * (1 - phat) / n)\n  \n  prop_df &lt;- tibble(phat, lb, ub)\n  return(prop_df)\n}\n\ngenerate_samp_prop(n = 10, p = 0.9)\n\n# A tibble: 1 × 3\n   phat    lb    ub\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1   0.8 0.592  1.01\n\n## how many CI's do we want\nn_sim &lt;- 5000\n\nprop_ci_df5 &lt;- map(1:n_sim, \n    \\(i) generate_samp_prop(n = 10, p = 0.9)) |&gt;\n  bind_rows()\n\nprop_ci_df5\n\n# A tibble: 5,000 × 3\n    phat    lb    ub\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1   0.6 0.345 0.855\n 2   0.9 0.744 1.06 \n 3   1   1     1    \n 4   1   1     1    \n 5   1   1     1    \n 6   0.9 0.744 1.06 \n 7   0.9 0.744 1.06 \n 8   0.9 0.744 1.06 \n 9   0.6 0.345 0.855\n10   1   1     1    \n# ℹ 4,990 more rows\n\n\nAverage interval width and coverage rate\n\nprop_ci_df5 &lt;- prop_ci_df5 |&gt; mutate(ci_width = ub - lb,\n                   ci_cover_ind = if_else(p2 &gt; lb & p2 &lt; ub,\n                                          true = 1,\n                                          false = 0))\nprop_ci_df5 |&gt; summarise(avg_width = mean(ci_width),\n                      coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.234         0.636\n\n\n\nTable of Results\n\n\n\n\n\n\n\n\n\n\n\n\\(n = 1000\\)\n\\(n = 100\\)\n\\(n = 10\\)\n\n\n\n\n\\(p = 0.45\\)\nCoverage Rate\n0.8916\n0.8878\n0.8016\n\n\n\\(p = 0.90\\)\nCoverage Rate\n0.8932\n0.8632\n0.635\n\n\n\n\n\n\n\n\n\n\\(p = 0.45\\)\nAverage Width\n0.05173266\n0.1628876\n0.4882621\n\n\n\\(p = 0.90\\)\nAverage Width\n0.03114799\n0.09735256\n0.2351569\n\n\n\nWrite-up:\nMy table of results shows the coverage rates and average widths for 90% confidence intervals for six different settings of a different sample size and population proportion. The coverage rates are closest to 90% level when the sample size is large, particularly for n = 1000, which makes sense for what we’ve been discussing in class. For both p = 0.45 and p = 0.9, the coverage rates are around 0.89, which is consistent with the confidence level. However, as the sample size decreases, the coverage rate tends to fall below 90%, especially for p = 0.9. This result highlights how smaller sample sizes are more likely to produce confidence intervals that do not contain the true population proportion, usually when the population proportion is far away from 0.5.\nThe average interval widths also show an expected pattern that we’ve discussed in class briefly. Larger sample sizes produce narrower confidence intervals, while smaller sample sizes make wider intervals. The average width for n = 1000 is significantly smaller than for n = 100 and n = 10, proving that there are more precise estimates with larger samples. For each sample size, the intervals are wider when p = 0.45 compared to p = 0.9. This happens because proportions near 0.5 have more variability making the confidence intervals wider.\nThese results prove the importance of the large sample assumption for the asymptotic confidence interval. When both n*p and n(1-p) are large, the intervals are more accurate and consistent with the theoretical confidence level. When these assumptions are violated with small sample sizes or extreme population proportions, the coverage rate decreases and the confidence intervals become less accurate. My simulation shows why we need to be careful when we apply asymptotic methods to small sample sizes (n = 10) or highly skewed population distributions (p = 0.9)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Math Stat Blog",
    "section": "",
    "text": "Reflection:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMini Project 1\n\n\n\n\n\n\n\n\n\n\n\nApr 28, 2025\n\n\nAbby Sikora\n\n\n\n\n\n\n\n\n\n\n\n\nMini Project 2\n\n\n\n\n\n\n\n\n\n\n\nApr 28, 2025\n\n\nAbby Sikora\n\n\n\n\n\n\n\n\n\n\n\n\nMini Project 3\n\n\n\n\n\n\n\n\n\n\n\nApr 28, 2025\n\n\nAbby Sikora\n\n\n\n\n\n\n\n\n\n\n\n\nMini Project 4\n\n\n\n\n\n\n\n\n\n\n\nApr 28, 2025\n\n\nAbby Sikora\n\n\n\n\n\n\n\n\n\n\n\n\nMini Project 5\n\n\n\n\n\n\n\n\n\n\n\nApr 28, 2025\n\n\nAbby Sikora\n\n\n\n\n\n\nNo matching items"
  }
]